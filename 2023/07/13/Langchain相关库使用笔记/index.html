<!DOCTYPE html><html lang="zh-CN"><head><meta name="google-site-verification" content="5gxi3jUweASrRKq85aC6vDUx5slnkZ7WLyLD0EhyplY"><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="V" href="http://yjfyqfzs.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="V" href="http://yjfyqfzs.github.io/atom.xml"><link rel="alternate" type="application/json" title="V" href="http://yjfyqfzs.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="http://yjfyqfzs.github.io/2023/07/13/Langchain%E7%9B%B8%E5%85%B3%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"><title>Langchain相关库使用笔记 | Archive of yh = V</title><meta name="generator" content="Hexo 6.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Langchain相关库使用笔记</h1><div class="meta"><span class="item" title="创建时间：2023-07-13 07:43:03"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2023-07-13T07:43:03+08:00">2023-07-13</time></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Archive of yh</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="/2023/07/13/Langchain%E7%9B%B8%E5%85%B3%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/mycover.png"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://yjfyqfzs.github.io/2023/07/13/Langchain%E7%9B%B8%E5%85%B3%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yihanW"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="V"></span><div class="body md" itemprop="articleBody"><h2 id="chatgpt-api基本调用"><a class="anchor" href="#chatgpt-api基本调用">#</a> ChatGPT API 基本调用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_completion</span>(<span class="params">prompt, model=<span class="string">&quot;gpt-3.5-turbo&quot;</span></span>):</span><br><span class="line">    messages = [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;]</span><br><span class="line">    response = openai.ChatCompletion.create(</span><br><span class="line">        model=model,</span><br><span class="line">        messages=messages,</span><br><span class="line">        temperature=<span class="number">0</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> response.choices[<span class="number">0</span>].message[<span class="string">&quot;content&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#token相关</span></span><br><span class="line">    token_dict = &#123;</span><br><span class="line"><span class="string">&#x27;prompt_tokens&#x27;</span>:response[<span class="string">&#x27;usage&#x27;</span>][<span class="string">&#x27;prompt_tokens&#x27;</span>],</span><br><span class="line"><span class="string">&#x27;completion_tokens&#x27;</span>:response[<span class="string">&#x27;usage&#x27;</span>][<span class="string">&#x27;completion_tokens&#x27;</span>],</span><br><span class="line"><span class="string">&#x27;total_tokens&#x27;</span>:response[<span class="string">&#x27;usage&#x27;</span>][<span class="string">&#x27;total_tokens&#x27;</span>],</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#moderation相关:https://platform.openai.com/docs/guides/moderation/overview，用于辨别有害信息</span></span><br><span class="line">response = openai.Moderation.create(</span><br><span class="line">    <span class="built_in">input</span>=<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Here&#x27;s the plan.  We get the warhead, </span></span><br><span class="line"><span class="string">and we hold the world ransom...</span></span><br><span class="line"><span class="string">...FOR ONE MILLION DOLLARS!</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">)</span><br><span class="line">moderation_output = response[<span class="string">&quot;results&quot;</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(moderation_output)</span><br></pre></td></tr></table></figure><h2 id="langchain使用"><a class="anchor" href="#langchain使用">#</a> Langchain 使用</h2><p>Langchain 是一个能够连接外部数据源与 LLM 模型的库，目前几乎所有需要结合本地数据库调用 LLM 模型接口的应用都基于 Langchain 实现。其调用流程如下图，本地数据导入后经过分割存储在向量库中，在提问时先从向量库中搜索相似的片段，作为描述词的上下文与用户自定义的描述词拼接作为 LLM 模型的输入。</p><div align="center"><img data-src="/2023/07/13/Langchain%E7%9B%B8%E5%85%B3%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/img1.png" width="800"></div><h3 id="常用格式文件的加载方式"><a class="anchor" href="#常用格式文件的加载方式">#</a> 常用格式文件的加载方式</h3><p><strong>PDF</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> PyPDFLoader<span class="comment">#需要先下载pypdf模块</span></span><br><span class="line">loader = PyPDFLoader(<span class="string">&quot;test.pdf&quot;</span>)</span><br><span class="line">pages = loader.load()</span><br></pre></td></tr></table></figure><p><code>pages</code> 为列表，每一页是一个 <code>Document</code> ，注意页数不一定与 pdf 页数相同。每个 <code>Document</code> 包括 <code>page_content</code> (该页所有文本) 和 <code>metadata</code> (该页信息)，如下图所示</p><div align="center"><img data-src="/2023/07/13/Langchain%E7%9B%B8%E5%85%B3%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/img2.png" width="400"></div><p><strong>txt 或 md</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> TextLoader</span><br><span class="line">loader = TextLoader(<span class="string">&quot;test.txt&quot;</span>,encoding=<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line"><span class="comment">#loader = TextLoader(&quot;test.md&quot;,encoding=&#x27;utf8&#x27;)</span></span><br><span class="line">documents = loader.load()</span><br></pre></td></tr></table></figure><p>此时 <code>documents</code> 中只包含一个 <code>Document</code></p><p>除了以上几种格式加载外，Langchain 还有 <code>DirectoryLoader</code> , <code>CSVLoader</code> , <code>JSONLoader</code> 等模块。</p><h3 id="文本分割"><a class="anchor" href="#文本分割">#</a> 文本分割</h3><p>Langchain 中对于一般文本使用 <code>RecursiveCharacterTextSplitter</code> 或 <code>CharacterTextSplitter</code> 分割，推荐使用 <code>RecursiveCharacterTextSplitter</code> ，使用方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line">chunk_size =<span class="number">26</span> <span class="comment">#分割每块的大小</span></span><br><span class="line">chunk_overlap = <span class="number">4</span> <span class="comment">#与上文重叠的大小</span></span><br><span class="line"></span><br><span class="line">r_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=chunk_size,</span><br><span class="line">    chunk_overlap=chunk_overlap,</span><br><span class="line">    separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>]<span class="comment">#分割符号，可不加此参数</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#分割string类型</span></span><br><span class="line">text1 = <span class="string">&#x27;abcdefghijklmnopqrstuvwxyz&#x27;</span></span><br><span class="line">r_splitter.split_text(text1)<span class="comment">#返回string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#分割导入的文件</span></span><br><span class="line">docspl=r_splitter.split_documents(documents)<span class="comment">#返回Document类型</span></span><br></pre></td></tr></table></figure><p>此外还可以使用 <code>TokenTextSplitter</code> 拆分，将以上代码中 <code>RecursiveCharacterTextSplitter</code> 替换为 <code>TokenTextSplitter</code> 即可。对于具有特定头结构的文件，可使用 <code>MarkdownHeaderTextSplitter</code> 拆分。</p><p>对于中文文本，可以使用阿里达摩院的<span class="exturl" data-url="aHR0cHM6Ly9tb2RlbHNjb3BlLmNuL21vZGVscy9kYW1vL25scF9iZXJ0X2RvY3VtZW50LXNlZ21lbnRhdGlvbl9jaGluZXNlLWJhc2UvcXVpY2tzdGFydA==">通用语义分割模型</span>进行文本分割。</p><h3 id="构建向量库"><a class="anchor" href="#构建向量库">#</a> 构建向量库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建embedding</span></span><br><span class="line"><span class="keyword">from</span> langchain.embeddings.openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line"><span class="comment">#embedding1 = embeddings.embed_query(sentence1)#对string类型构建embedding</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建vectorstore，需要先安装chromadb</span></span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line">persist_directory = <span class="string">&#x27;db&#x27;</span></span><br><span class="line">vectorstore = Chroma.from_documents(documents, embedding=embeddings,persist_directory=persist_directory)<span class="comment">#若直接从string列表中读取，用from_texts</span></span><br><span class="line"><span class="comment">#vectorstore.persist()#保存</span></span><br><span class="line"><span class="comment">#vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)#读入</span></span><br><span class="line"><span class="comment">#docs = vectordb.similarity_search(question_str,k=3)#相似性搜索</span></span><br><span class="line"><span class="comment">#docs.max_marginal_relevance_search(question_str,k=2, fetch_k=3)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>若要从 <code>query</code> 中搜索相似数据，可采用以下方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.retrievers.self_query.base <span class="keyword">import</span> SelfQueryRetriever</span><br><span class="line"><span class="keyword">from</span> langchain.chains.query_constructor.base <span class="keyword">import</span> AttributeInfo</span><br><span class="line"></span><br><span class="line">metadata_field_info = [</span><br><span class="line">    AttributeInfo(</span><br><span class="line">        name=<span class="string">&quot;source&quot;</span>,</span><br><span class="line">        description=<span class="string">&quot;The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`&quot;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">    AttributeInfo(</span><br><span class="line">        name=<span class="string">&quot;page&quot;</span>,</span><br><span class="line">        description=<span class="string">&quot;The page from the lecture&quot;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&quot;integer&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">document_content_description = <span class="string">&quot;Lecture notes&quot;</span></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">retriever = SelfQueryRetriever.from_llm(</span><br><span class="line">    llm,</span><br><span class="line">    vectordb,</span><br><span class="line">    document_content_description,</span><br><span class="line">    metadata_field_info,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">question = <span class="string">&quot;what did they say about regression in the third lecture?&quot;</span></span><br><span class="line">docs = retriever.get_relevant_documents(question)</span><br></pre></td></tr></table></figure><p>当文本过长时，可以使用 <code>ContextualCompressionRetriever</code> 模块来压缩，使用方法如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.retrievers <span class="keyword">import</span> ContextualCompressionRetriever</span><br><span class="line"><span class="keyword">from</span> langchain.retrievers.document_compressors <span class="keyword">import</span> LLMChainExtractor</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pretty_print_docs</span>(<span class="params">docs</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n<span class="subst">&#123;<span class="string">&#x27;-&#x27;</span> * <span class="number">100</span>&#125;</span>\n&quot;</span>.join([<span class="string">f&quot;Document <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>:\n\n&quot;</span> + d.page_content <span class="keyword">for</span> i, d <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs)]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Wrap our vectorstore</span></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">compressor = LLMChainExtractor.from_llm(llm)</span><br><span class="line"></span><br><span class="line">compression_retriever = ContextualCompressionRetriever(</span><br><span class="line">    base_compressor=compressor,</span><br><span class="line">    base_retriever=vectordb.as_retriever()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">question = <span class="string">&quot;what did they say about matlab?&quot;</span></span><br><span class="line">compressed_docs = compression_retriever.get_relevant_documents(question)</span><br><span class="line">pretty_print_docs(compressed_docs)</span><br></pre></td></tr></table></figure><h3 id="调用llm模型"><a class="anchor" href="#调用llm模型">#</a> 调用 LLM 模型</h3><p>简单调用方式:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line">llm = ChatOpenAI(model_name=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">llm.predict(<span class="string">&quot;Hello world!&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>设置提示词模板</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.output_parsers <span class="keyword">import</span> StructuredOutputParser, ResponseSchema</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义提取信息的格式</span></span><br><span class="line">response_schemas = [</span><br><span class="line">    ResponseSchema(name=<span class="string">&quot;时间&quot;</span>, description=<span class="string">&quot;事件的时间&quot;</span>),</span><br><span class="line">    ResponseSchema(name=<span class="string">&quot;主体&quot;</span>, description=<span class="string">&quot;执行事件的人&quot;</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化解析器</span></span><br><span class="line">output_parser = StructuredOutputParser.from_response_schemas(response_schemas)</span><br><span class="line">format_instructions = output_parser.get_format_instructions()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义描述词模板</span></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一个数据分析师,你的任务是从用户输入的一段事件中,根据以下要求提取和输出信息</span></span><br><span class="line"><span class="string">&#123;format_instructions&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">% USER INPUT:</span></span><br><span class="line"><span class="string">&#123;user_input&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">YOUR RESPONSE:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将模板嵌入提示词</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;user_input&quot;</span>],</span><br><span class="line">    partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: format_instructions&#125;,</span><br><span class="line">    template=template</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">promptValue = prompt.<span class="built_in">format</span>(user_input=<span class="string">&quot;2023年9月1日,小明去上学了&quot;</span>)<span class="comment">#返回string</span></span><br><span class="line">llm_output = llm(promptValue)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用解析器进行解析生成的内容</span></span><br><span class="line">output_parser.parse(llm_output)<span class="comment">#返回dic</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>此外还可以创建 <code>chain</code> 来回答，最常用的 chain 为 <code>RetrievalQA</code> 和 <code>ConversationalRetrievalChain</code> , 示例如下:</p><p><code>RetrievalQA</code> 示例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line">template = <span class="string">&quot;&quot;&quot;Use the following pieces of context to answer the question at the end. If you don&#x27;t know the answer, just say that you don&#x27;t know, don&#x27;t try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say &quot;thanks for asking!&quot; at the end of the answer. </span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">Question: &#123;question&#125;</span></span><br><span class="line"><span class="string">Helpful Answer:&quot;&quot;&quot;</span></span><br><span class="line">QA_CHAIN_PROMPT = PromptTemplate(input_variables=[<span class="string">&quot;context&quot;</span>, <span class="string">&quot;question&quot;</span>],template=template)<span class="comment">##使用RetrievalQA必须要有&quot;context&quot;变量,表示向量库搜索的文本,后续不用在input_data指定</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run chain</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line">question = <span class="string">&quot;Is probability a class topic?&quot;</span></span><br><span class="line">qa_chain = RetrievalQA.from_chain_type(llm,</span><br><span class="line">                                       retriever=vectordb.as_retriever(),</span><br><span class="line">                                       return_source_documents=<span class="literal">True</span>,</span><br><span class="line">                                       chain_type_kwargs=&#123;<span class="string">&quot;prompt&quot;</span>: QA_CHAIN_PROMPT&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">result = qa_chain(&#123;<span class="string">&quot;question&quot;</span>: question,<span class="string">&quot;context&quot;</span>:context&#125;)</span><br><span class="line">result[<span class="string">&quot;result&quot;</span>]</span><br></pre></td></tr></table></figure><p><code>ConversationalRetrievalChain</code> 示例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">    return_messages=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationalRetrievalChain</span><br><span class="line">retriever=vectordb.as_retriever()</span><br><span class="line">qa = ConversationalRetrievalChain.from_llm(</span><br><span class="line">    llm,</span><br><span class="line">    retriever=retriever,</span><br><span class="line">    memory=memory</span><br><span class="line">)</span><br><span class="line">question = <span class="string">&quot;Is probability a class topic?&quot;</span></span><br><span class="line">result = qa(&#123;<span class="string">&quot;question&quot;</span>: question&#125;)</span><br><span class="line">result[<span class="string">&#x27;answer&#x27;</span>]</span><br></pre></td></tr></table></figure><p>openai 更新了 GPT 相关 api, 可以以 json 格式输出回答 (<span class="exturl" data-url="aHR0cHM6Ly9wbGF0Zm9ybS5vcGVuYWkuY29tL2RvY3MvZ3VpZGVzL2dwdC9jaGF0LWNvbXBsZXRpb25zLWFwaQ==">https://platform.openai.com/docs/guides/gpt/chat-completions-api</span>), 目前 Langchain 已添加了相关函数调用，具体示例可参考:<span class="exturl" data-url="aHR0cHM6Ly9weXRob24ubGFuZ2NoYWluLmNvbS9kb2NzL21vZHVsZXMvY2hhaW5zL2FkZGl0aW9uYWwvb3BlbmFpX2Z1bmN0aW9uc19yZXRyaWV2YWxfcWE=">https://python.langchain.com/docs/modules/chains/additional/openai_functions_retrieval_qa</span></p><h2 id="langchain衍生库使用"><a class="anchor" href="#langchain衍生库使用">#</a> Langchain 衍生库使用</h2><h3 id="llama_index使用"><a class="anchor" href="#llama_index使用">#</a> llama_index 使用</h3><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2plcnJ5amxpdS9sbGFtYV9pbmRleA==">llama_index</span> 是一个基于 Langchain 的库，专门用于连接本地数据与 LLM 模型。更新较快，此处以 0.0.65 版为例<br>需要导入以下模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> SimpleDirectoryReader,GPTListIndex,GPTSimpleVectorIndex,LLMPredictor,PromptHelper,ServiceContext</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_index</span>(<span class="params">path</span>):</span><br><span class="line">  docs = SimpleDirectoryReader(path).load_data() <span class="comment">#load data</span></span><br><span class="line">  vectorIndex = GPTSimpleVectorIndex.from_documents(documents=docs) <span class="comment">#create vector index</span></span><br><span class="line">  vectorIndex.save_to_disk(<span class="string">&#x27;vectorIndex.json&#x27;</span>)</span><br><span class="line">  <span class="keyword">return</span> vectorIndex</span><br></pre></td></tr></table></figure><p>以上函数加载指定路径中的文档 (txt,doc 等)，并经过 embedding 将文档表示为向量，存入 json 文件中。<strong>GPTSimpleVectorIndex</strong> 默认使用 &quot;text-davinci-003&quot;, 也可以自行定义 &quot;service_context&quot; 参数，定义方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Getservice_con</span>():</span><br><span class="line">  llm_predictor = LLMPredictor(llm=OpenAI(temperature=<span class="number">0</span>, model_name=<span class="string">&quot;text-davinci-003&quot;</span>))</span><br><span class="line">  <span class="comment">#llm_predictor=LLMPredictor(llm=ChatOpenAI(model_name=&quot;gpt-3.5-turbo&quot;,temperature=0))</span></span><br><span class="line">  <span class="comment"># define prompt helper</span></span><br><span class="line">  <span class="comment"># set maximum input size</span></span><br><span class="line">  max_input_size = <span class="number">4096</span></span><br><span class="line">  <span class="comment"># set number of output tokens</span></span><br><span class="line">  num_output = <span class="number">128</span></span><br><span class="line">  <span class="comment"># set maximum chunk overlap</span></span><br><span class="line">  max_chunk_overlap = <span class="number">20</span></span><br><span class="line">  prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)    </span><br><span class="line">  service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)  </span><br><span class="line">  <span class="comment">#service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor) </span></span><br><span class="line">  <span class="keyword">return</span> service_context    </span><br></pre></td></tr></table></figure><p>service_context 可作为参数输入 <code>GPTSimpleVectorIndex</code> ，即 <code>GPTSimpleVectorIndex.from_documents(documents=docs,service_context=service_context)</code> 。此外 <code>prompt_helper</code> 中的各项参数可以直接输入 <code>service_context</code> ，例如 <code>service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=1024)</code></p><p>调用 LLM 模型接口时，从保存的 json 文件中搜索与描述词相近的向量，作为上下文与描述词同时输入 LLM 模型接口</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">answerMe</span>(<span class="params">vectorIndex,service_context</span>):</span><br><span class="line">  vIndex = GPTSimpleVectorIndex.load_from_disk(vectorIndex)</span><br><span class="line">  <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    input_data = <span class="built_in">input</span>(<span class="string">&#x27;Please ask: &#x27;</span>)</span><br><span class="line">    response = vIndex.query(input_data,response_mode=<span class="string">&quot;compact&quot;</span>,service_context=ser)<span class="comment">#service_context定义调用的LLM接口参数</span></span><br><span class="line">    <span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure><h3 id="kor库使用"><a class="anchor" href="#kor库使用">#</a> Kor 库使用</h3><p><span class="exturl" data-url="aHR0cHM6Ly9leXVydHNldi5naXRodWIuaW8va29yL3R1dG9yaWFsLmh0bWw=">Kor 库</span> 主要用于从文本中提取结构化数据，使用时一般需要导入以下库并定义 LLM 模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> kor.extraction <span class="keyword">import</span> create_extraction_chain</span><br><span class="line"><span class="keyword">from</span> kor.nodes <span class="keyword">import</span> Object, Text,Selection,Option</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model_name=<span class="string">&quot;gpt-3.5-turbo&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0</span>,</span><br><span class="line">    max_tokens=<span class="number">2000</span>,</span><br><span class="line">    frequency_penalty=<span class="number">0</span>,</span><br><span class="line">    presence_penalty=<span class="number">0</span>,</span><br><span class="line">    top_p=<span class="number">1.0</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>Text</code> , <code>Selection</code> , <code>Option</code> 为 <code>Object</code> 的三种常用属性。Text 简单模式示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">schema = Object(</span><br><span class="line">    <span class="built_in">id</span>=<span class="string">&quot;person&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;Personal information&quot;</span>,</span><br><span class="line">    examples=[</span><br><span class="line">        (<span class="string">&quot;Alice and Bob are friends&quot;</span>, [&#123;<span class="string">&quot;first_name&quot;</span>: <span class="string">&quot;Alice&quot;</span>&#125;, &#123;<span class="string">&quot;first_name&quot;</span>: <span class="string">&quot;Bob&quot;</span>&#125;])</span><br><span class="line">    ],</span><br><span class="line">    attributes=[</span><br><span class="line">        Text(</span><br><span class="line">            <span class="built_in">id</span>=<span class="string">&quot;first_name&quot;</span>,</span><br><span class="line">            description=<span class="string">&quot;The first name of a person.&quot;</span>,</span><br><span class="line">        )</span><br><span class="line">    ],</span><br><span class="line">    many=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>注意，<strong> <code>id</code> 只能用英文表示</strong></p><p>创建链并设置新的问题</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chain = create_extraction_chain(llm, schema)</span><br><span class="line">response=chain.predict_and_parse(text=(<span class="string">&quot;My name is Bobby. My brother&#x27;s name Joe.&quot;</span>))[<span class="string">&quot;data&quot;</span>]</span><br></pre></td></tr></table></figure><p>输出为 <code>&#123;'person': [&#123;'first_name': 'Bobby'&#125;, &#123;'first_name': 'Joe'&#125;]&#125;</code></p><p>使用 <code>print(chain.prompt.format_prompt(text=&quot;[user input]&quot;).to_string())</code> 可获取输入大语言模型的描述词</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Your goal <span class="keyword">is</span> to extract structured information <span class="keyword">from</span> the use<span class="string">r&#x27;s input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`TypeScript</span></span><br><span class="line"><span class="string">person: Array&lt;&#123; // Personal information</span></span><br><span class="line"><span class="string"> first_name: string // The first name of a person.</span></span><br><span class="line"><span class="string">&#125;&gt;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Please output the extracted information in CSV format in Excel dialect. Please use a | as the delimiter. </span></span><br><span class="line"><span class="string">Do NOT add any clarifying information. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Input: Alice and Bob are friends</span></span><br><span class="line"><span class="string">Output: first_name</span></span><br><span class="line"><span class="string">Alice</span></span><br><span class="line"><span class="string">Bob</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Input: [user input]</span></span><br><span class="line"><span class="string">Output:</span></span><br></pre></td></tr></table></figure><p>当 schema 中有多个 attributes 时，<strong>example 中要包括所有 attributes 中的参数</strong>，以 Selection 类型为例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sel = Selection(</span><br><span class="line">    <span class="built_in">id</span>=<span class="string">&quot;name_type&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;Whether the sentence show the name is of a boy or girl&quot;</span>,</span><br><span class="line">    options=[</span><br><span class="line">        Option(<span class="built_in">id</span>=<span class="string">&quot;boy&quot;</span>, description=<span class="string">&quot;boy&#x27;s name&quot;</span>),</span><br><span class="line">        Option(<span class="built_in">id</span>=<span class="string">&quot;girl&quot;</span>, description=<span class="string">&quot;girl&#x27;s name&quot;</span>),</span><br><span class="line">        Option(<span class="built_in">id</span>=<span class="string">&quot;none&quot;</span>, description=<span class="string">&quot;not sure&quot;</span>),</span><br><span class="line">    ],</span><br><span class="line">    many=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>当结构写为以下形式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">schema = Object(</span><br><span class="line">    <span class="built_in">id</span>=<span class="string">&quot;person&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;Personal information&quot;</span>,</span><br><span class="line">    attributes=[</span><br><span class="line">        Text(</span><br><span class="line">            <span class="built_in">id</span>=<span class="string">&quot;first_name&quot;</span>,</span><br><span class="line">            description=<span class="string">&quot;The first name of a person.&quot;</span>,</span><br><span class="line">        ),sel</span><br><span class="line">    ],</span><br><span class="line">    examples=[</span><br><span class="line">        (<span class="string">&quot;Alice and Bob are friends&quot;</span>, [&#123;<span class="string">&quot;first_name&quot;</span>: <span class="string">&quot;Alice&quot;</span>&#125;, &#123;<span class="string">&quot;first_name&quot;</span>: <span class="string">&quot;Bob&quot;</span>&#125;,&#123;<span class="string">&quot;name_type&quot;</span>:<span class="string">&quot;none&quot;</span>&#125;])</span><br><span class="line">    ],</span><br><span class="line">    many=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>输入大模型的描述词为:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Your goal <span class="keyword">is</span> to extract structured information <span class="keyword">from</span> the use<span class="string">r&#x27;s input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`TypeScript</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">person: Array&lt;&#123; // Personal information</span></span><br><span class="line"><span class="string"> first_name: string // The first name of a person.</span></span><br><span class="line"><span class="string"> name_type: &quot;boy&quot; | &quot;girl&quot; | &quot;none&quot; // Whether the sentence show the name is of a boy or girl</span></span><br><span class="line"><span class="string">&#125;&gt;</span></span><br><span class="line"><span class="string">`</span></span><br><span class="line"><span class="string">Please output the extracted information in CSV format in Excel dialect. Please use a | as the delimiter. </span></span><br><span class="line"><span class="string"> Do NOT add any clarifying information. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Input: Alice and Bob are friends</span></span><br><span class="line"><span class="string">Output: first_name|name_type</span></span><br><span class="line"><span class="string">Alice|</span></span><br><span class="line"><span class="string">Bob|</span></span><br><span class="line"><span class="string">|none</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Input: [user input]</span></span><br><span class="line"><span class="string">Output:</span></span><br></pre></td></tr></table></figure><p>当 <code>schema</code> 中 <code>examples</code> 的每条属性分批书写，例如以下写法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">examples=[</span><br><span class="line">    (<span class="string">&quot;Alice and Bob are friends&quot;</span>, [&#123;<span class="string">&quot;first_name&quot;</span>: <span class="string">&quot;Alice&quot;</span>&#125;, &#123;<span class="string">&quot;first_name&quot;</span>: <span class="string">&quot;Bob&quot;</span>&#125;]),</span><br><span class="line">    (<span class="string">&quot;Alice and Bob are friends&quot;</span>, [&#123;<span class="string">&quot;name_type&quot;</span>:<span class="string">&quot;none&quot;</span>&#125;])</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>则输入大模型的描述词中，示例写为:</p><pre><code>
Input: Alice and Bob are friends
Output: first_name|name_type
Alice|
Bob|

Input: Alice and Bob are friends
Output: first_name|name_type
|none
</code></pre><p>不正确</p></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2023-07-14 07:51:32" itemprop="dateModified" datetime="2023-07-14T07:51:32+08:00">2023-07-14</time> </span><span id="2023/07/13/Langchain相关库使用笔记/" class="item leancloud_visitors" data-flag-title="Langchain相关库使用笔记" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>yihanW <i class="ic i-at"><em>@</em></i>V</li><li class="link"><strong>本文链接：</strong> <a href="http://yjfyqfzs.github.io/2023/07/13/Langchain%E7%9B%B8%E5%85%B3%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/" title="Langchain相关库使用笔记">http://yjfyqfzs.github.io/2023/07/13/Langchain相关库使用笔记/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2023/05/25/XiaozhengChat/" itemprop="url" rel="prev" data-background-image="&#x2F;2023&#x2F;05&#x2F;25&#x2F;XiaozhengChat&#x2F;mycover.png" title="基于GPT与本地知识库的数字人聊天应用"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>基于GPT与本地知识库的数字人聊天应用</h3></a></div><div class="item right"></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#chatgpt-api%E5%9F%BA%E6%9C%AC%E8%B0%83%E7%94%A8"><span class="toc-number">1.</span> <span class="toc-text">ChatGPT API 基本调用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#langchain%E4%BD%BF%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">Langchain 使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E6%A0%BC%E5%BC%8F%E6%96%87%E4%BB%B6%E7%9A%84%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F"><span class="toc-number">2.1.</span> <span class="toc-text">常用格式文件的加载方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E5%88%86%E5%89%B2"><span class="toc-number">2.2.</span> <span class="toc-text">文本分割</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E5%90%91%E9%87%8F%E5%BA%93"><span class="toc-number">2.3.</span> <span class="toc-text">构建向量库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%83%E7%94%A8llm%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.4.</span> <span class="toc-text">调用 LLM 模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#langchain%E8%A1%8D%E7%94%9F%E5%BA%93%E4%BD%BF%E7%94%A8"><span class="toc-number">3.</span> <span class="toc-text">Langchain 衍生库使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#llama_index%E4%BD%BF%E7%94%A8"><span class="toc-number">3.1.</span> <span class="toc-text">llama_index 使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kor%E5%BA%93%E4%BD%BF%E7%94%A8"><span class="toc-number">3.2.</span> <span class="toc-text">Kor 库使用</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yihanW" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yihanW</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">8</span> <span class="name">文章</span></a></div></nav><div class="social"></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/2022/12/09/Ue%E8%93%9D%E5%9B%BE%E4%BF%AE%E6%94%B9Sequence/" title="Ue蓝图修改Sequence">Ue蓝图修改Sequence</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/01/05/GithubHexo/" title="Hexo+Github博客搭建">Hexo+Github博客搭建</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/07/13/Langchain%E7%9B%B8%E5%85%B3%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/" title="Langchain相关库使用笔记">Langchain相关库使用笔记</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/01/18/ueplug/" title="ue插件">ue插件</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/12/15/MayaApi/" title="Maya Api笔记">Maya Api笔记</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/05/25/XiaozhengChat/" title="基于GPT与本地知识库的数字人聊天应用">基于GPT与本地知识库的数字人聊天应用</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/12/02/DNAimg/" title="MetahumanDNA校准库">MetahumanDNA校准库</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/03/04/UeMayaControlRig/" title="Python实现Unreal和Maya传输Metahuman面部控制器数据">Python实现Unreal和Maya传输Metahuman面部控制器数据</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yihanW @ Archive of yh</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2023/07/13/Langchain相关库使用笔记/",favicon:{show:"Good",hide:"Boom"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>